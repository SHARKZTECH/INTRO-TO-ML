{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1f8mpfd3SLWejSj5nbkt6h3PIRZHshqw_",
      "authorship_tag": "ABX9TyOwkF/Y3NCgOU17FeFtQAKz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SHARKZTECH/INTRO-TO-ML/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9pbtj2BN3-EV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://github.com/Karan-Malik/Chatbot/blob/master/chatbot_codes/intents.json //Dataset\n",
        "- https://www.kaggle.com/datasets/niraliivaghani/chatbot-dataset //More dataset\n"
      ],
      "metadata": {
        "id": "ng1AKT5gpGEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Types of Chat Bot's\n",
        "In the world of machine learning and AI there are many different kinds of chat bots. Some chat bots are virtual assistants, others are just there to talk to, some are customer support agents and you've probably seen some of the ones used by businesses to answer questions. For this tutorial we will be creating a relatively simple chat bot that will be be used to answer frequently asked questions."
      ],
      "metadata": {
        "id": "2cM1z6DN3-HA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fLNvnjOf4kTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflearn"
      ],
      "metadata": {
        "id": "SC295rvX4kU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe17ce72-334b-41f5-8f14-9024938ab56d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tflearn) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tflearn) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tflearn) (8.4.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127283 sha256=dd541c8ec02ec295f0f08bc68f77a5d4bcc12e2af151a2bb424d2c9985de445c\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/fb/7b/e06204a0ceefa45443930b9a250cb5ebe31def0e4e8245a465\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "import tflearn\n",
        "import random\n",
        "import json\n",
        "\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()"
      ],
      "metadata": {
        "id": "wL_p7-gr4FKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5c47d7-69fc-4333-fc60-54580de10e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/intents.json') as file:\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "id": "T6Gl6aGV4r8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Wt2SS3m9W7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b68fULx9W9B",
        "outputId": "25331a74-ca4e-418a-93df-d2b64ac747d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "labels = []\n",
        "docs_x = []\n",
        "docs_y = []\n",
        "\n",
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        wrds = nltk.word_tokenize(pattern)\n",
        "        words.extend(wrds)\n",
        "        docs_x.append(wrds)\n",
        "        docs_y.append(intent[\"tag\"])\n",
        "\n",
        "    if intent['tag'] not in labels:\n",
        "        labels.append(intent['tag'])"
      ],
      "metadata": {
        "id": "m5uAJAHC5Ghv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Stemming\n",
        "Stemming a word is attempting to find the root of the word. For example, the word \"thats\" stem might be \"that\" and the word \"happening\" would have the stem of \"happen\". We will use this process of stemming words to reduce the vocabulary of our model and attempt to find the more general meaning behind sentences"
      ],
      "metadata": {
        "id": "b2WLv2GO9eoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "labels = sorted(labels)"
      ],
      "metadata": {
        "id": "bane7UdQ9v34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of Words\n",
        "- We need to rep string in numbers for ANN.\n",
        " What we are going to do is represent each sentence with a list the length of the amount of words in our models vocabulary. Each position in the list will represent a word from our vocabulary. If the position in the list is a 1 then that will mean that the word exists in our sentence, if it is a 0 then the word is nor present. We call this a bag of words because the order in which the words appear in the sentence is lost, we only know the presence of words in our models vocabulary.\n",
        "- As well as formatting our input we need to format our output to make sense to the neural network. Similarly to a bag of words we will create output lists which are the length of the amount of labels/tags we have in our dataset. Each position in the list will represent one distinct label/tag, a 1 in any of those positions will show which label/tag is represented."
      ],
      "metadata": {
        "id": "kBHpkEU3-UQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training = []\n",
        "output = []\n",
        "\n",
        "out_empty = [0 for _ in range(len(labels))]\n",
        "\n",
        "for x, doc in enumerate(docs_x):\n",
        "    bag = []\n",
        "\n",
        "    wrds = [stemmer.stem(w.lower()) for w in doc]\n",
        "\n",
        "    for w in words:\n",
        "        if w in wrds:\n",
        "            bag.append(1)\n",
        "        else:\n",
        "            bag.append(0)\n",
        "\n",
        "    output_row = out_empty[:]\n",
        "    output_row[labels.index(docs_y[x])] = 1\n",
        "\n",
        "    training.append(bag)\n",
        "    output.append(output_row)"
      ],
      "metadata": {
        "id": "yaoB26WL_PT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally we will convert our training data and output to numpy arrays.\n",
        "\n",
        "training = np.array(training)\n",
        "output = np.array(output)"
      ],
      "metadata": {
        "id": "pm1BnH1G_RmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Developing a Model\n",
        "Now that we have preprocessed all of our data we are ready to start creating and training a model. For our purposes we will use a fairly standard feed-forward neural network with two hidden layers. The goal of our network will be to look at a bag of words and give a class that they belong too (one of our tags from the JSON file)."
      ],
      "metadata": {
        "id": "X3ILn8kq_yIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "net = tflearn.input_data(shape=[None, len(training[0])])\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n",
        "net = tflearn.regression(net)\n",
        "\n",
        "model = tflearn.DNN(net)"
      ],
      "metadata": {
        "id": "tUHwmHaA_8ri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f160077d-c14e-4052-b29e-066e58f72046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tflearn/initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPysRPLFrFPw",
        "outputId": "1266d79f-0161-4820-b53a-e9ed2c1f5445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Step: 6999  | total loss: \u001b[1m\u001b[32m0.00441\u001b[0m\u001b[0m | time: 0.026s\n",
            "| Adam | epoch: 1000 | loss: 0.00441 - acc: 1.0000 -- iter: 48/50\n",
            "Training Step: 7000  | total loss: \u001b[1m\u001b[32m0.00434\u001b[0m\u001b[0m | time: 0.029s\n",
            "| Adam | epoch: 1000 | loss: 0.00434 - acc: 1.0000 -- iter: 50/50\n",
            "--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.tflearn\")"
      ],
      "metadata": {
        "id": "P3c5EMHArFSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training & Saving the Model\n",
        "\n",
        "try:\n",
        "    model.load(\"model.tflearn\")  # Loading a Model\n",
        "\n",
        "except:\n",
        "    model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
        "    model.save(\"model.tflearn\")"
      ],
      "metadata": {
        "id": "PKZcPFYyA6Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making Predictions\n",
        "\n",
        "def bag_of_words(s, words):\n",
        "    bag = [0 for _ in range(len(words))]\n",
        "\n",
        "    s_words = nltk.word_tokenize(s)\n",
        "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
        "\n",
        "    for se in s_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == se:\n",
        "                bag[i] = 1\n",
        "\n",
        "    return np.array(bag)\n",
        "\n",
        "\n",
        "def chat():\n",
        "    print(\"Start talking with the bot (type quit to stop)!\")\n",
        "    while True:\n",
        "        inp = input(\"You: \")\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        results = model.predict([bag_of_words(inp, words)])\n",
        "        results_index = np.argmax(results)\n",
        "        tag = labels[results_index]\n",
        "\n",
        "        for tg in data[\"intents\"]:\n",
        "            if tg['tag'] == tag:\n",
        "                responses = tg['responses']\n",
        "\n",
        "        print(random.choice(responses))\n",
        "\n",
        "chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WOUhw0xADBn",
        "outputId": "dfa17c5a-7185-4422-c633-9a026b8e99fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start talking with the bot (type quit to stop)!\n",
            "You: hey\n",
            "Good to see you again\n",
            "You: sjthgfvkyugiuhiuhuhu\n",
            "See you later, thanks for visiting\n",
            "You: hllo thre\n",
            "Bye! Come back again soon.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hToMnmkWCW_V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}